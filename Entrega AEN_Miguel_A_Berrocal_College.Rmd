---
title: "EMOD Entrega College"
author: "Miguel Ángel Berrocal"
date: "12/2/2017"
output: pdf_document
---

## Introducción.

En este ejercicio se hace uso del conjunto de datos "College", disponible en el paquete de R (ISLR)

En esta práctica se determinará un modelo tipo gam para la variable respuesta **GradRate**, eligiendo la función más adecuada para cada variable predictora. La valoración de los modelos se realizará a través del Criterio de Información de Akaike (AIC), tal y como se procedió en el problema anterior (Autos).

```{r, message=FALSE, warning=FALSE}
library(ISLR)
library(gam)
library(ggplot2)
library(corrplot)
library(car)
```

```{r}
str(College)
attach(College)
```

El conjunto de datos está constituido por 777 observaciones con 18 variables predictoras. La variable **Private** es de tipo factor, mientras que el resto de variables son de tipo numéricas. Si se desea obtener información adicional de cada variable, ejecutar la instrucción **?College**.

A continuación, se muestra el significado de cada una de ellas.

### Variables explicativas.

**Private**: A factor with levels No and Yes indicating private or public university

**Apps**: Number of applications received

**Accept**: Number of applications accepted

**Enroll**: Number of new students enrolled

**Top10perc**: Pct. new students from top 10% of H.S. class

**Top25perc**: Pct. new students from top 25% of H.S. class

**F.Undergrad**: Number of fulltime undergraduates

**P.Undergrad**: Number of parttime undergraduates

**Outstate**: Out-of-state tuition

**Room.Board**: Room and board costs

**Books**: Estimated book costs

**Personal**: Estimated personal spending

**PhD**: Pct. of faculty with Ph.D.'s

**Terminal**: Pct. of faculty with terminal degree

**S.F.Ratio**: Student/faculty ratio

**perc.alumni**: Pct. alumni who donate

**Expend**:Instructional expenditure per student

### Variable respuesta:

**Grad.Rate**:Graduation rate


## Análisis de los datos.


Una vez introducido el problema, se pasa a estudiar la distribución de la variable respuesta. Para ello se representa su histograma.

```{r}
p <- ggplot(College, aes(x=Grad.Rate)) + 
  geom_histogram(position = "identity", col= "red", fill="white", alpha = 0.5, bins= 20)

p + ggtitle("Histograma de la tasa de graduados.")

```

A la vista del histograma se aprecia que la variable respuesta, **Grad.Rate**, sigue una distribución parecida a una normal. Para contrastarlo, se usa el test de normalidad de Shapiro Wilk.

```{r}
shapiro.test(College$Grad.Rate)
```

Se recuerda que el test plantea como hipótesis nula que una muestra X1,...,Xn proviene de una población normalmente distribuida. En este caso, como el p-valor resultante es menor que 0.05, se rechaza la hipótesis nula, y por tanto, no se puede asegurar que las muestras sigan una distribución normal.

Por otro lado, se tiene que **Private** es una variable categórica, y la variable respuesta podría ser susceptible de presentar valores diferentes en función de si una universidad es pública o privada. La siguiente figura presenta un gráfico de puntos donde se representa la tasa de graduación para todos los casos, discriminando por la variable **Private**

```{r}
x <- array(1:length(College$Grad.Rate))

privados=which(College$Private=="Yes")
d_priv=College[privados,"Grad.Rate"]
publicos=which(College$Private=="No")
d_pub=College[publicos,"Grad.Rate"]

a<-qplot(x,Grad.Rate, data = College, colour = Private,
      main = "Tasa de graduación en función de la variable Private")

a + geom_hline(yintercept = c(mean(d_priv), mean(d_pub)), 
               colour=c("#1FBFC3","#F57670"), alpha=I(0.65))
  
```

Si bien es cierto que hay mas casos de universidades privadas que públicas y que la tasa de graduación en las universidades privadas es mayor, la variable **Private** no es determinante a la hora de establecer un tasa de graduación, y por tanto, no parece sensato dividir a la población en dos subconjuntos discriminando por esta variable.


## Eliminación de valores atípicos y selección de variables.

Sobre el gráfico, se puede observar la existencia de varios casos atípicos que podrían resultar de interés eliminarlos del conjuto de datos. Para detectar estos valores atípicos y averiguar sus índices se ejecuta la siguiente instrucción:

### Localización y eliminación de outliers.

```{r}
outliers <- boxplot(College$Grad.Rate, main='Valores atípicos en la tasa de graduación', 
                    ylab='Grad.Rate', col = 'lightblue')
# Valores atípicos
values <- outliers$out
(indices <- which(College$Grad.Rate %in% values))
# Nuevos datos con los outliers eliminados
datos_sin_outliers <- College[-indices,]
str(datos_sin_outliers)

```

Una vez eliminados los casos atípicos, se procederá a determinar la correlación entre las variables que componen el modelo para poder determinar la relevancias de éstas y poder establecer un criterio de selección. La función **corrplot** permite visualizar de forma cómoda la matriz de correlaciones entre variables.

### Localización y eliminación de variables correlacionadas.

```{r}
# Se deja fuera la variable respuesta y Private por ser categórica
corr_matrix <- cor(datos_sin_outliers[,-c(1,18)])
corrplot(corr_matrix,method="ellipse")
```

Se genera también un modelo lineal, a través del cuál se podrá estimar la importancia relativa de las variables, y junto con la imagen anterior, tomar las variables de partida más adecuadas para generar los modelos.

```{r}
modelo_completo=lm(Grad.Rate~.,data=datos_sin_outliers)
summary(modelo_completo)
```

Con la información que se dispone, y tomando como criterio que las variables susceptibles de ser eliminidas del modelo son aquellas que presentan una correlación >= 0.85 en valor absoluto y son menos significativas, se ha decidido eliminar las siguientes variables explicativas: **Terminal, F.Undergrad, Top10perc, Accept y Enroll**. Además, se van a eliminar aquellas con un nivel de significación bajo, como **books, S.F. Ratio y PhD**

```{r}
datos_utiles = datos_sin_outliers[,-c(3,4,5,7,11,13,14,15)]
names(datos_utiles)
modelo_reducido=lm(Grad.Rate~.,data=datos_utiles)
summary(modelo_reducido)
```

Al eliminar las variables propuestas se ha reducido considerablemente el número de variables predictoras, quedando, sin embargo, un valor de R^2 muy cercano al que se tenía en el modelo con todas las variables.

### Visualización de las variables seleccionadas y la relación entre ellas.

En este punto, se puede representar un gráfico de puntos en el que se midan las relaciones entre los diferentes pares de variables. Como se puede comprobar, no hay una dependencia clara entre ningún par, debido al proceso de selección realizado en los apartados anteriores.

```{r}
pairs(~Grad.Rate + Private + Apps + Top25perc + Outstate + P.Undergrad + Room.Board 
      + Personal + perc.alumni + Expend  , data=datos_utiles)
```

A continuación, se presenta un gráfico para facilitar la compresión de cómo se relacionan varias de las variables explicativas con la variable respuesta.

```{r}

p <- qplot(Top25perc, Grad.Rate, data = datos_utiles, col= Private, size= Outstate, 
           alpha = I(0.65),
           main = "Tasa de graduación frente a diferentes variables representativas") 

privados=which(datos_utiles$Private=="Yes")
d_priv=datos_utiles[privados,"Grad.Rate"]
publicos=which(datos_utiles$Private=="No")
d_pub=datos_utiles[publicos,"Grad.Rate"]

p + geom_hline(yintercept = c(mean(d_priv), mean(d_pub)), 
               colour=c("#1FBFC3","#F57670"), alpha=I(0.65))
```

Sobre la figura anterior se pueden sacar ciertas consideraciones. Como se comentó anteriormente, se corrobora que la variable **Private** no resulta tan discriminante como para tratar las dos categorías que la componen de forma separada. También se encuentra cierta relación con la variable **Outstate**, amentando la tasa de graduados conforme aumenta esta variable.

## Aplicación de los modelos.

En este último paso, se trata de averiguar qué función es la más adecuada para cada variable predictora de las seleccionadas. Las funciones a aplicar serán splines y polinómicas, denotadas en como **s** y **poly** respectivamente. Los grados posibles que van a tomar las variables está comprendidos entre 0 y 4. Para el caso de grado = 0, no se aplicará ninguna función a la variable implicada.

Para la selección de las funciones adecuadas, se propone un algoritmo constructivo e iterativo que permite generar combinaciones aleatorias de las funciones propuestas y sus grados, y aplicarlas a las diferentes variables. 

Este algoritmo surge de la necesidad de generar difentes combinaciones de selección de variables y aplicación de funciones, ya que, a priori, no se puede establecer un método secuencial que asegure la combinación óptima de dichos parámetros, o de poder realizarse, sería muy costoso computacionalmente.

Se ha decidido implementar el método en este paso, dado que las tareas previa como el estudio de las variables y la selección de atributos no tienen un carácter aleatorio y se debe realizar justificando las decisiones tomadas de forma analítica.

En primer lugar, se elimina la variable respuesta de las candidatas a ser implementadas en el modelo. Se tendrán, por tanto, 9 variables con las que hacer combinaciones.

```{r}
# Creación del modelo de trabajo eliminando la variable respuesta
datos_modelo <- datos_utiles[,-c(10)]
n_var = length(datos_modelo)
```

Se ha denominado método constructivo e iterativo por las siguientes razones:

**Constructivo**: El algoritmo construye modelos crecientes en complejidad, comenzando por dos variables y finalizando con todas (9).

**Iterativo**: Para cada iteración en la que se seleccionan **i** variables, se generan **j** modelos aleatorios. Randomizando el tipo de función a aplicar, su grado y el orden de inclusión de las variables.

Inicialmente, se parte de dos variables. Para estas variables se generan 30 modelos aleatorios. Para cada modelo, se toman las variables de forma aleatoria, tal que los 30 modelos aleatorios de dos variables no estén formados siempre por las mismas. Para cada variable seleccionada, se elige de forma aleatoria si se le aplica una función de tipo splin o polinómica, además, también se determina su grado. En el caso de que el grado seleccionado sea cero, a esa variable no se le aplica función alguna. 

Una vez generado el modelo, se toma su valor AIC y se compara con el mejor valor obtenido con los modelos anteriores. Si el nuevo valor es el mejor encontrado hasta ese momento, se almacena y se toma su AIC como el de referencia. Para facilitar su compresión, se ha guardado el histórico de los valores AIC para su posterior representación gráfica a modo de curva de aprendizaje.

Una vez generados y evaluados los 30 modelos de 2 variables, se incrementa en 1 el número de variables a incluir en el siguiente modelo y se repite el proceso anterior. El algoritmo termina cuando se han incluido todas las variables del modelo reducido (9).



```{r}
# Inicialización de las variables.
best_score = Inf
iteraciones = 0
historico.aic = 0
historico.var.numbers = 0
primero = 1

# Se introducen las variables al modelo de una en una. Se comienza con 2 variables
for  (i in 2:n_var){
  
  # Se realiza el proceso 30 veces para que se generen un buen numero de combinaciones
  for (j in 1:30){
  
    # Se recoge una muestra desordenada de tamaño i
    muestra <-sample(1:n_var,n_var,replace=FALSE)[1:i]
    # Se seleccionan las columnas correspondientes a la muestra generada
    names_muestra = names(datos_modelo)[muestra]
    
    # Para cada variable se elige si se aplica splines o poly y su grado
    vars = ""
    for (v in 1:i){
      
        # Si dice = 1 uso splines, sino uso poly
        dice = sample(c("s","poly"), 1)
        # Indica el grado del polinomio generado
        grade = sample(0:4, 1)
      
      # Si la variable es Private o el grado es 0 no se aplica ninguna función
      if (names_muestra[v] == "Private" || grade == 0){
        var = names_muestra[v]
      }else{
        if (dice == "s"){
          var = paste("s(",names_muestra[v],",",grade,")", sep = "")
        }else{ 
          var = paste("poly(",names_muestra[v],",",grade,")", sep = "")
        }
      }
      # Si no es la última variable del modelo se añade el símbolo +
      if (v < i){
        vars = paste(vars, var," + ", sep = "")
      }else{
        vars = paste(vars, var, sep = "")
      }
    }
    # Generación de la sentencia a aplicar en el modelo
    model_vars = paste("Grad.Rate ~ ", vars)
    # Ejecución del modelo
    expresion = as.formula(model_vars)
    model = gam(expresion, data=datos_utiles)
    
    # Almacenamiento de los valores AIC
    iteraciones = iteraciones + 1 
   
     if (primero==1){
      historico.aic = model$aic
      iteracion = 1
      num.var = i
      primero = 0
      
    }else{
      historico.aic = rbind(historico.aic,model$aic)
      num.var = rbind(num.var,i)
    }
    
    # Si el modelo ejecutado es mejor que el almacenado, se actualiza el mejor modelo.
    if (model$aic < best_score){
      best_score = model$aic
      best_model = model
      best_index = iteraciones
    }
  }
}

```


Una vez aplicado el algoritmo, se tiene que el mejor modelo resultante, entendiendo como mejor aquel con menor AIC es el siguiente:

```{r}
# AIC del mejor modelo
best_score
# Fórmula del mejor modelo
best_model$formula
```

Por último, se representa la curva de aprendizaje del algoritmo, donde se observa la tendencia de mejora conforme el aumento de número de variables en el modelo. El color de cada punto depende del número de variables incluidas en el modelo, siendo más oscuro cuanto menor número de variables implicadas.

```{r}
qplot(1:iteraciones, historico.aic, col=num.var, main= "Curva de aprendizaje") 
```

Para verificar finalmente que las variables propuestas son las más adecuadas, a modo de justificación, se va a repetir el proceso anterior, pero esta vez con todas las variables.

```{r}
# Inicialización de las variables.
datos_modelo <- datos_sin_outliers[,-c(18)]
n_var = length(datos_modelo)

best_score = Inf
iteraciones = 0
historico.aic = 0
historico.var.numbers = 0
primero = 1

# Se introducen las variables al modelo de una en una. Se comienza con 2 variables
for  (i in 2:n_var){
  
  # Se realiza el proceso 30 veces para que se generen un buen numero de combinaciones
  for (j in 1:30){
  
    # Se recoge una muestra desordenada de tamaño i
    muestra <-sample(1:n_var,n_var,replace=FALSE)[1:i]
    # Se selecciona las columnas correspondientes a la muestra genera
    names_muestra = names(datos_modelo)[muestra]
    
    # Para cada variable se elige si se aplica splines o poly y su grado
    vars = ""
    for (v in 1:i){
      
        # Si dice = 1 uso splines, sino uso poly
        dice = sample(c("s","poly"), 1)
        # Indica el grado del polinomio generado
        grade = sample(0:4, 1)
      
      # Si la variable es Private o el grado es 0 no se aplica ninguna función
      if (names_muestra[v] == "Private" || grade == 0){
        var = names_muestra[v]
      }else{
        if (dice == "s"){
          var = paste("s(",names_muestra[v],",",grade,")", sep = "")
        }else{ 
          var = paste("poly(",names_muestra[v],",",grade,")", sep = "")
        }
      }
      # Si no es la última variable del modelo se añade el símbolo +
      if (v < i){
        vars = paste(vars, var," + ", sep = "")
      }else{
        vars = paste(vars, var, sep = "")
      }
    }
    # Generación de la sentencia a aplicar en el modelo
    model_vars = paste("Grad.Rate ~ ", vars)
    # Ejecución del modelo
    expresion = as.formula(model_vars)
    model = gam(expresion, data=datos_sin_outliers)
    
    # Almacenamiento de los valores AIC
    iteraciones = iteraciones + 1 
   
     if (primero==1){
      historico.aic = model$aic
      iteracion = 1
      num.var = i
      primero = 0
      
    }else{
      historico.aic = rbind(historico.aic,model$aic)
      #iteracion = rbind(iteracion,iteraciones)
      num.var = rbind(num.var,i)
    }
    
    # Si el modelo ejecutados es mejor que el almacenado, se actualiza el mejor modelo.
    if (model$aic < best_score){
      best_score = model$aic
      best_model = model
    }
  }
}

# Valor del mejor modelo
best_score
# Fórmula del mejor modelo
best_model$formula

qplot(1:iteraciones, historico.aic, col=num.var, main= "Curva de aprendizaje")

```

Como se comprueba con el valor AIC, el modelo generado con todas las variables no mejora de forma significativa al descrito en el aparatado anterior, al cual se le aplicó la selección de variables.

Como conclusión, se extrae que con la simple aplicación de un algoritmo estilo Montecarlo, se facilita al investigador la tarea de seleccionar las mejores funciones para cada variable. Este método de búsqueda podría mejorarse mediante la aplicación de meteheurísticas tales como algoritmos genéticos o búsqueda tabú, sin embargo, para conjuntos de datos con pocas variables no resulta necesario.


```{r echo=FALSE}
detach(College)
```